{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b63ecd2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b63ecd2b",
    "outputId": "f37b85e9-cddf-4c22-cb2f-0a95f4a3e238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AI in healthcare to Improve Patient Outcomes\n",
      "Article Text: Friday, April 14, 2023Sign in / JoinSearchHomeWhat We ThinkAI in healthcare to Improve Patient OutcomesAI in healthcare to Improve Patient OutcomesBy Ajay BidyarthyJune 26, 2021023929Introduction\n",
      "“If anything kills over 10 million people in the next few decades, it will be a highly infectious virus rather than a war. Not missiles but microbes.” Bill Gates’s remarks at a TED conference in 2014, right after the world had avoided the Ebola outbreak. When the new, unprecedented, invisible virus hit us, it met an overwhelmed and unprepared healthcare system and oblivious population. This public health emergency demonstrated our lack of scientific consideration and underlined the alarming need for robust innovations in our health and medical facilities. For the past few years, artificial intelligence has proven to be of tangible potential in the healthcare sectors, clinical practices, translational medical and biomedical research.\n",
      "After the first case was detected in China on December 31st 2019, it was an AI program developed by BlueDot that alerted the world about the pandemic. It was quick to realise AI’s ability to analyse large chunks of data could help in detecting patterns and identifying and tracking the possible carriers of the virus.\n",
      "Many tracing apps use AI to keep tabs on the people who have been infected and prevent the risk of cross-infection by using AI algorithms that can track patterns and extract some features to classify or categorise them.\n",
      "So how does AI do that?\n",
      "IBM Watson, a sophisticated AI that works on cloud computing and natural language processing, has prominently contributed to the healthcare sector on a global level. Being a conversational AI, since 2013, Watson has helped in recommending treatments to patients suffering from cancer to ensure that they get the best treatment at optimum costs.\n",
      "\n",
      "Researchers at Google Inc. showed that an AI system can be trained on thousands of images to achieve physician-level sensitivity.\n",
      "By identifying the molecular patterns associated with disease status and its subtypes, gene expression, and protein abundance levels, machine learning methods can detect fatal diseases like cancer at an early stage. Machine Learning (ML) techniques focus mainly on analyzing structured data, which can further help in clustering patients’ traits and infer the probability of disease outcomes. Since patient traits mainly include masses of data relating to age, gender, disease history, disease-specific data like diagnostic imaging and gene expressions, etc, ML can extract features from these data inputs by constructing data analytical algorithms.\n",
      "ML algorithms are either supervised or unsupervised. Unsupervised learning helps in extracting features and clustering similar features together that further leads to early detection of diseases. Clustering and principal component analysis enable grouping or clustering of similar traits together that are further used to maximize or minimize the similarity between the patients within or between the clusters. Since patient traits are recorded in multiple dimensions, such as genes, principal component analysis(PCA) creates the apparatus to reduce these dimensions which humans could have not done alone.\n",
      "Supervised learning considers the outcomes of the subjects together with the traits, and further correlates the inputs with the outputs to predict the probability of getting a particular clinical event, expected value of a disease level or expected survival time, or risk of Down’s syndrome.\n",
      "Biomarker panels that are mostly used to detect ovarian cancer, have outperformed the conventional statistical methods due to machine learning. In addition to this, the use of EHRs and Bayesian networks, which are a part of supervised machine learning algorithms, can predict clinical outcomes and mortality respectively.\n",
      "Unstructured data such as clinical notes and texts are converted into machine-readable structured data with the help of natural language processing(NLP). NLP works with two components: text processing and classification. Text processing helps in identifying a series of disease-relevant keywords in clinical notes and then through classification are further categorized into normal and abnormal cases. Chest screening through ML and NLP has helped find abnormalities in the lungs and provide treatment to covid patients. Healthcare organizations use NLP-based chatbots to increase interactions with patients, keeping their mental health and wellness in check.\n",
      "Deep learning is a modern extension of the classical neural network techniques which helps explore more complex non-linear patterns in data, using algorithms like convolution neural network, recurrent neural network, deep belief network, and deep neural network which enables more accurate clinical prediction. When it comes to genome interpretation, deep neural networks surpass the conventional methods of logistics regression and support vector machines.\n",
      "Sepsis Watch is an AI system trained in deep learning algorithms that holds the capability to analyze over 32 million data points to create a patient’s risk score and identify the early stages of sepsis.\n",
      "Another method known as the Learning-based Optimization of the Under Sampling Pattern( LOUPE) is based on integrating full resolution MRI scans with the convolutional neural network algorithm, which helps in creating more accurate reconstructions.\n",
      "Robotic surgery is widely considered in most delicate surgeries like gynaecology and prostate surgery. Even after striking the right balance between human decisions and AI precision, robotic surgery reduces surgeon efficiency as they have to be manually operated through a console. Thus, autonomous robotic surgery is on the rise with inventions such as robotic silicon fingers that mimic the sense of touch that surgeons need to identify organs, cut tissues, etc., or robotic catheters that can navigate whether it is touching blood, tissue, or valve.\n",
      "Researchers at Children’s National Hospital, Washington have already developed an AI called Smart Tissue Autonomous Robot (STAR), which performs a colon anastomosis on its own with the help of an ML-powered suturing tool, that automatically detects the patient’s breathing pattern to apply suture at the correct point.\n",
      "An image of STAR during surgery.\n",
      "Cloud computing in healthcare has helped in retrieving and sharing medical records safely with a reduction in maintenance costs. Through this technology doctors and various healthcare workers have access to detailed patient data that helps in speeding up analysis ultimately leading to better care in the form of more accurate information, medications, and therapies.\n",
      "How can It help in Biomedical research?\n",
      "Since AI can analyze literature beyond readability, it can be used to concise biomedical research. With the help of ML algorithms and NLP, AI can accelerate screening and indexing of biomedical research, by ranking the literature of interest which allows researchers to formulate and test scientific hypotheses far more precisely and quickly. Taking it to the next level, AI systems like the computational modelling assistant (CMA) helps researchers to construct simulation models from the concepts they have in mind. Such innovations have majorly contributed to topics such as tumour suppressor mechanisms and protein-protein interaction information extraction.\n",
      "AI as precision medicine\n",
      "Since precision medicine focuses on healthcare interventions to individuals or groups of patients based on their profile, the various AI devices pave the way to practice it more efficiently. With the help of ML, complex algorithms like large datasets can be used to predict and create an optimal treatment strategy.\n",
      "Deep learning and neural networks can be used to process data in healthcare apps and keep a close watch on the patient’s emotional state, food intake, or health monitoring. \n",
      "“Omics” refers to the collective technologies that help in exploring the roles, relationships of various branches ending with the suffix “omics” such as genomics, proteomics, etc. Omics-based tests based on machine learning algorithms help find correlations and predict treatment responses, ultimately creating personalized treatments for individual patients. \n",
      "How it helps in psychology and neuro patients\n",
      "For psychologists studying creativity,  AI is promising new classes of experiments that are developing data structures and programs and exploring novel theories on a new horizon. Studies show that  AI can conduct therapy sessions, e-therapy sessions, and assessments autonomously, also assisting human practitioners before, during, or after sessions. The Detection and Computational Analysis of Psychological Signal project uses ML, computer vision, and NLP to analyze language, physical gestures, and social signals to identify cues for human distress. This ground-breaking technology assesses soldiers returning from combat and recognizes those who require further mental health support. In the future, it will combine data captured during face-to-face interviews with information on sleeping, eating, and online behaviours for a complete patient view.\n",
      "Stroke identification\n",
      "Stroke is another frequently occurring disease that affects more than 500 million people worldwide. Thrombus,  in the vessel cerebral infarction is the major (about 85%) cause of stroke occurrence. In recent years, AI techniques have been used in numerous stroke-related studies as early detection and timely treatment along with efficient outcome prediction can help solve the problem. With AI at our disposal, large amounts of data with rich information, more complications and real-life clinical questions can be addressed in this arena. Currently, two ML algorithms- genetic fuzzy finite state machine and PCA were implemented to build a model building solution. These include a human activity recognition stage and a stroke onset detection stage. An alert stroke message is activated as soon as a movement significantly different from the normal pattern is recorded. ML methods have been applied to neuroimaging data to assist disease evaluation and predicting stroke treatment for the diagnosis.\n",
      "Patient Monitoring\n",
      "Today, the market for AI-based patient monitoring is impressive and monetarily enticing. It is evolving with artificial sensors, smart technologies and explores everything from brain-computer interfaces to nanorobotics. Companies with their smart-watches have engaged people to perform remote monitoring even when they are not “patients”. An obvious place to start is with wearable and embedded sensors, glucose monitors, pulse monitors, oximeters, and ECG monitors. With patient monitoring becoming crucial, AI finds numerous applications in chronic conditions, intensive care units, operating rooms, emergency rooms, and cardiac wards where timeless clinical decision-making can be measured in seconds. More advances have started to gain traction like smart prosthetics and implants. These play an impeccable role in patient management post-surgery or rehabilitation. Demographics, laboratory results and vital signs can also be used to predict cardiac arrest, transfer into the intensive care unit, or even death. In addition, an interpretable machine-learning model can assist anesthesiologists in predicting hypoxaemia events during surgery. This suggests that with deep-learning algorithms, raw patient-monitoring data could be better used to avoid information overload and alert overload while enabling more accurate clinical prediction and timely decision-making.\n",
      "\n",
      " Conclusion\n",
      "Considering the vast range of tasks that an AI can do, it is evident that it holds deep potential in improving patient outcomes to skyrocketing levels. Using sophisticated algorithms AI can bring a revolution in the healthcare sector. Even after facing challenges like whether the technology will be able to deliver the promises, ethical measures, training physicians to use it, standard regulations etc, the role of AI in transforming the clinical practices cannot be ignored. The biggest challenge is the integration of AI in daily practice. All of these can be overcome and within that period the technologies will mature making the system far more enhanced and effective.\n",
      "Blackcoffer Insights 29: Sanskriti Sunderum and Aayushi Nauhwar, SRCC, Delhi UniversityTagsAIalgorithmCovidHealthcareMlpandemicpatient outcomesPrevious articleWhat if the Creation is Taking Over the Creator?Next articleFuture of AI and Machine Roles in the Medical SectorAjay Bidyarthy\n",
      "Article saved to URL_ID 37.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='tdb-title-text').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='tdb-block-inner td-fix-index'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 37.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d287d96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d287d96",
    "outputId": "05343d66-9c7b-4a43-b41f-0fe100e6c561"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: What if the Creation is Taking Over the Creator?\n",
      "Article Text: Human minds, a fascination in itself carrying the potential of tinkering nature with the pixie dust intelligence, creating and solving the mysteries and wonders with anything but admiration. However, no matter how captivating a human mind can be, it could sometimes be appalled. It could be the hunger or maybe the desire to want more, to go beyond and unravel the limitations, or maybe something like pure greed. Humans have never stopped and always keep evolving when it comes to intelligence and this is what makes them the supreme.\n",
      "Intelligence calls out for supremacy and so, what if there was to evolve something that opposed a challenge to the very human minds, to their capabilities while making them question their own importance among themselves? Artificial Intelligence came as a revolution, havoc when it first came to the light. The concept of making machines does work on their own, like granting machines –The Intelligence.\n",
      "The idea of making machines work like humans came back in the 19s. Back then people didn’t believe in such a thing as making a non-living thing work, think, and carry tasks on its own, not to mention, to actually surpass humans themselves in those skills. The facts are it did. By 1997. The greatest chess player, Garry Kasparov was defeated in a chess game by a machine and this is where exactly, a top skilled human lost to a mere machine created by another who by himself could’ve never defeated him. It was a rule of power, of betterment, of skills, and the granted supremacy. Were AI and Machines just tools? Equipment?  Something that helped an unskilled person with his mind and intelligence creates something that could do the skilled work for him with perfection and precision? Well initially it was, however, as time passed as humans got drawn to the puzzle of AI, a lot changed. Human research went deeper and deeper and as a result, the machines evolved with it.\n",
      "At present, AI & Machines is a growing field. As it develops and improves, it has become a part of the industrial revolution. In industries, most of the laborious work that was once taken care of by humans was now replaced by machines. Naturally, with the evolution in machines, its precision, mass productivity, quality control, time efficiencies, and all the other factors made it a better choice. A choice over humans.\n",
      "This led to fear, a fear of a not-so-distant future, a future where maybe machines will be so evolved that they’ll take over the need of a human employee leading to unemployment. With the population increase around the world, it became the new tech threat for the labor market. Then again… how true is it? Does AI really oppose a threat? Will adapting to technology make millions of people lose their jobs? Will it lead to mass unemployment? Will the machines really surpass humans? Will, the creation take over the creator?\n",
      "No matter how fearful the future with AI may seem, in reality, it is not that scary. Truth is AI is the present reality, it is the key that holds the power to unlock a whole next level of human evolution. Technology is growing. There was a time where technology was just an idea, but today that idea has been implemented, it’s working and is carried out. Nobody could stop the advancement and growth of Artificial Intelligence, it’s a wave that is already flowing and we as the present generation and the generations to come to have to learn, to learn to swim in this flow and avoid drowning.\n",
      "Many jobs will be replaced by machines, as AI evolves it’ll keep challenging human minds and their skills. With the present COVID 19 situation, contactless cashiers to robots delivering packages have already taken over the usual routine tasks. The jobs of Secretaries, Schedulers, and book-keeper are at risk too. Manufacturing units, agriculture, food services, retail, transportation & logistic, and hospitality are all a part of the AI-affected automation. At an estimation, it is said that around 20 million jobs, especially including manufacturing will be lost to robots. As AI, robotics, 3D printing, and genetics make their way in, even the architects, medical docs, and music composers feel threatened by technology. Making us question that will AI even edge us out of our brain jobs too? Now that can be terrifying.\n",
      "However, as much as machines will be replacing few jobs, they’ll also be creating new jobs.  With the economic growth, innovation, and investment around 133 million jobs are said to be generated. These newly enhanced jobs are to create benefits and amplify one’s creativity, strategy, and entrepreneurial skills. So what is the catch?\n",
      "Well, it’s the skills. Even though AI is creating 3 times more jobs than it is destroying, it’s the skills that count. AI surged in new job opportunities, opportunities like Senior Data Scientist, Mobile Application Developer, and SEO specialist. These jobs were once never heard of but now with AI it’s born, however, to do these jobs or for its qualification, one needs high-level skills and to acquire those skills can be an expensive and time-consuming task. The future generation might be able to cope up with it but the real struggle is to be faced by the present two generations. It’s the vulnerability between the skill gap and unemployment and the youths are the ones to be crushed the most.\n",
      "Therefore, as the advancement of AI becomes inevitable there remains no choice but to adapt, learn, equip ourselves and grow with it. The companies have to work together to build an AI-ready workplace. They should collaborate with the government, educators, and non-profit organizations and work together to bring out policies that could help understand the technologies’ impacts faster while also providing the employees some security. The economic and business planning should be made considerable for minimizing the impact on local jobs and properly maximizing the opportunities.\n",
      "The employees should be provided with proper tools to carry along with the new opportunities while acquiring AI-based skills for their day-to-day work. New skills should be identified and implemented for the upskilling and continual learning initiatives. Employees will have to maximize their Robotic Quotient and learn core skills. They’ll have to adapt to new working models and understand their roles in the coming future. \n",
      "Howsoever, it’s not like AI will totally take over control, even though AI proves to be a better choice, it still has its limitations at present. First, it’s expensive, secondly, manufacturing machines in bulk is not good for the environment. Machines are also very high maintenance, therefore human labor will often come cheaper and so will be considered over machines. Underdeveloped countries will find it hard to equip their people with the upskilling and reskilling required for AI workplace and so for AI to play a role in those countries, might take years. AI can also be risky and unethical, as it’s hard to figure out who to be held responsible for in cases where an AI went wrong.\n",
      "No matter, how advanced AI gets, there are some skills where humans will always have an upper hand i.e., soft skills. Skills like teamwork, communication, creativity, and critical thinking are something that AI hasn’t been able to beat us up to yet and so the value of creativity, leadership, and emotional intelligence has increased. Although, with machines coming in between humans causing the lack of human-to-human interaction, the humans seem to fade away a little.\n",
      "With this era, comes the need for good leaders. Leaders who are capable of handling both machines and humans together, the ones who are organized enough to manage the skilled and the unskilled employees while providing the unskilled trainees with proper training. Leaders who hold profound soft skills and encourage teamwork while working along with machines. The ones who are patient, calm, and optimized.  \n",
      "In conclusion, yes AI and machines are going to be very challenging but there’s nothing humans haven’t overcome. Adaptation and up-gradation are going to be the primary factor for survival. As we witness the onset of the 4th industrial revolution, let’s buckle up our seats and race along the highway with the essential fuels (skills) so as to not let ourselves eliminated. After all, this is an unending race with infinity as the end, all we could do is try not to run out of fuel. Try not to be outdated. \n",
      "Blackcoffer Insights 29: Glady, Karunya Institute of Technology and Sciences.\n",
      "Article saved to URL_ID 38.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/what-if-the-creation-is-taking-over-the-creator/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 38.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d2966b",
   "metadata": {
    "id": "38d2966b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7494830f",
   "metadata": {
    "id": "7494830f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c2597a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40c2597a",
    "outputId": "5eef7d83-f3af-472f-bf4b-5f8602a24cce"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/what-jobs-will-robots-take-from-humans-in-the-future/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 39.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4da3d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ab4da3d7",
    "outputId": "d204ca64-1c75-4f7a-da9d-394b77f12959"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/will-machine-replace-the-human-in-the-future-of-work/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 40.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc4a25d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5dc4a25d",
    "outputId": "19424b63-8263-4540-9e47-bb0fb5c17fbe"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/will-ai-replace-us-or-work-with-us/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 41.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8dd25f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b8dd25f",
    "outputId": "8be90a78-7128-46a8-c01a-444ef7ed8c9f"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/man-and-machines-together-machines-are-more-diligent-than-humans-blackcoffe/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 42.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387dd4ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "387dd4ce",
    "outputId": "bf6c846d-3133-4038-c49c-2e95264a6bf9"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/in-future-or-in-upcoming-years-humans-and-machines-are-going-to-work-together-in-every-field-of-work/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 43.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e444043",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e444043",
    "outputId": "1eec399e-d5b1-4f36-b958-9009c84663f0"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h3', class_='tdm-title tdm-title-md').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='tds-button td-fix-index'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 44.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a608c5f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a608c5f4",
    "outputId": "744e7a71-67cf-415d-e57a-6c4715321bb4"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-machine-learning-will-affect-your-business/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 45.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95802f51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95802f51",
    "outputId": "a7219918-4862-42b7-ef10-9df016a4d729"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/deep-learning-impact-on-areas-of-e-learning/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 46.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c60f2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9c60f2f",
    "outputId": "7c507e6f-1a72-417c-9a14-7b38bd70efa6"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-to-protect-future-data-and-its-privacy-blackcoffer/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 47.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f06b89c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7f06b89c",
    "outputId": "92e38898-0b9c-444d-b207-bdd8304d417d"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-machines-ai-automations-and-robo-human-are-effective-in-finance-and-banking/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 48.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8db7750",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8db7750",
    "outputId": "8cfbd6b6-619d-4806-811e-d1dfa4c6ee71"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/ai-human-robotics-machine-future-planet-blackcoffer-thinking-jobs-workplace/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 49.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6554b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cb6554b2",
    "outputId": "9a3a8226-a72d-4c4b-b4eb-d6e1c6d1eee9"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-ai-will-change-the-world-blackcoffer/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 50.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a85c168",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a85c168",
    "outputId": "0a1dd7c1-7fda-4cb0-dec2-fb53ca96b8ff"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/future-of-work-how-ai-has-entered-the-workplace/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='tdb-title-text').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='tdb-block-inner td-fix-index'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 51.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818a8da2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "818a8da2",
    "outputId": "d0d55dd2-66fe-4f91-fe00-e9281c2ef485"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/ai-tool-alexa-google-assistant-finance-banking-tool-future/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 52.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1108436f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1108436f",
    "outputId": "514ce04a-cf5d-44d1-9f50-333cda17f4c8"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/ai-healthcare-revolution-ml-technology-algorithm-google-analytics-industrialrevolution/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 53.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d71576",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1d71576",
    "outputId": "73289a05-71cb-455b-f00b-18339ac84791"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/all-you-need-to-know-about-online-marketing/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 54.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff56de0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ff56de0",
    "outputId": "82ea6e92-c67e-4ca9-c240-35a18b0701cf"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/evolution-of-advertising-industry/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 55.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7eba87",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d7eba87",
    "outputId": "db435db2-161b-4d83-9bfd-387be45aa22d"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-data-analytics-can-help-your-business-respond-to-the-impact-of-covid-19/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 56.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e534f1a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e534f1a1",
    "outputId": "1a0eb223-e628-4648-852b-75fe3a8ade19"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h3', class_='tdm-title tdm-title-md').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='tds-button td-fix-index'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 57.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9a4817",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d9a4817",
    "outputId": "99ee6601-788b-42a1-a2fe-bdb07580c6a9"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/environmental-impact-of-the-covid-19-pandemic-lesson-for-the-future/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 58.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc20abea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dc20abea",
    "outputId": "dc0f1215-df0e-4a93-cc9e-ee8ed1c11c31"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-data-analytics-and-ai-are-used-to-halt-the-covid-19-pandemic/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 59.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1414f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1f1414f1",
    "outputId": "e296ddcf-05bb-4530-d5c6-1ed6014ee19c"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/difference-between-artificial-intelligence-machine-learning-statistics-and-data-mining/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 60.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe3b01c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fe3b01c",
    "outputId": "e4797ca6-be2d-4e43-d733-d7f013575fa1"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-python-became-the-first-choice-for-data-science/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 61.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c8c636",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95c8c636",
    "outputId": "4721c976-e8d5-4c7e-8705-f2da8f505634"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-google-fit-measure-heart-and-respiratory-rates-using-a-phone/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 62.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56a4a76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d56a4a76",
    "outputId": "3a36c9af-0ef6-4847-aebb-41126eafbd76"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/what-is-the-future-of-mobile-apps/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 63.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a7983",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "108a7983",
    "outputId": "7c657d6d-773e-42e1-f333-a8623e0f9f87"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/impact-of-ai-in-health-and-medicine/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 64.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d34ee5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35d34ee5",
    "outputId": "ad12af8d-46b9-4a77-c992-0e0ab6bc9c14"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/telemedicine-what-patients-like-and-dislike-about-it/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 65.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b252c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51b252c6",
    "outputId": "117f4241-fd45-484f-dc43-c57a57fe895b"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-we-forecast-future-technologies/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 66.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d65ca71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3d65ca71",
    "outputId": "9bad49f2-dbf2-4b16-edc2-a0ed09a5c8a3"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/can-robots-tackle-late-life-loneliness/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 67.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d830d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5d830d3",
    "outputId": "4a0cacb6-6fd6-4fad-d8ad-c26d34fe6788"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/embedding-care-robots-into-society-socio-technical-considerations/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 68.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b6b211",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36b6b211",
    "outputId": "478177e2-ce7f-4d14-9985-f1014b644922"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/management-challenges-for-future-digitalization-of-healthcare-services/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 69.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334860de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "334860de",
    "outputId": "c36425e0-380f-4230-be88-4dda3961b2d7"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/are-we-any-closer-to-preventing-a-nuclear-holocaust/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 70.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5146e589",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5146e589",
    "outputId": "92929608-f911-4f8b-dd4f-d1404a9dac90"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/will-technology-eliminate-the-need-for-animal-testing-in-drug-development/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 71.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e86c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f38e86c1",
    "outputId": "ea667e55-4cd5-4876-ec9a-437c3782ad16"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/will-we-ever-understand-the-nature-of-consciousness/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 72.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be21e1cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "be21e1cc",
    "outputId": "6c1f81d1-bf95-422f-beb9-de81eca8a96c"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/will-we-ever-colonize-outer-space/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 73.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b1e49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "598b1e49",
    "outputId": "b0056012-90f5-45b6-8488-b19712d37d57"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/what-is-the-chance-homo-sapiens-will-survive-for-the-next-500-years/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 74.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff0842c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bff0842c",
    "outputId": "7a3cecc3-ef3d-49ec-bcb9-0b81d2b1eb08"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/why-does-your-business-need-a-chatbot/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 75.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5e078",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dd5e078",
    "outputId": "77f7fbb4-b5c3-410e-874a-c15cdaa4827c"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-you-lead-a-project-or-a-team-without-any-technical-expertise/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 76.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918500f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "918500f9",
    "outputId": "f129a258-2d9c-4589-e217-923dec9269a4"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/can-you-be-great-leader-without-technical-expertise/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 77.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f657ec6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8f657ec6",
    "outputId": "60e96237-661b-46d2-e05f-c60860c2adf2"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-does-artificial-intelligence-affect-the-environment/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 78.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f200be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47f200be",
    "outputId": "9cb1f9cc-7ce4-4ccd-ffdd-64754b409670"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes-2/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 79.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dfddbf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79dfddbf",
    "outputId": "eb497882-ecea-4b6d-b87c-df8b3385ec8e"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/is-perfection-the-greatest-enemy-of-productivity/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 80.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec0bd3b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cec0bd3b",
    "outputId": "3f428b1b-a350-4c3d-8c46-a90a14c5f458"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/global-financial-crisis-2008-causes-effects-and-its-solution/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 81.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e48cdd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99e48cdd",
    "outputId": "f20ba2c2-f5f0-46c9-b211-945ff549ce9e"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/gender-diversity-and-equality-in-the-tech-industry/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 82.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9823bc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9823bc9",
    "outputId": "811ce410-5e92-4aeb-8c4a-61bff095bdbd"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 83.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083a5352",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "083a5352",
    "outputId": "83c83fb6-1beb-4f7d-ca74-7cb4c448c45b"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-small-business-can-survive-the-coronavirus-crisis/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 84.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a79f10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71a79f10",
    "outputId": "ab297df6-7bd8-4cc4-ed8a-fca1691a6995"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors-and-food-stalls/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 85.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c651fc6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c651fc6b",
    "outputId": "e7ad38c7-21eb-4796-86bd-41a0a9ed4904"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 86.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121dd739",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "121dd739",
    "outputId": "a412ba8e-c827-4255-a08f-230735ea7575"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-tourism-aviation-industries/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 87.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b69c19b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3b69c19b",
    "outputId": "7d5879b3-7c17-4902-b8df-36860145768c"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-sports-events-around-the-world/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 88.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1325bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ef1325bd",
    "outputId": "e3dd0b89-fe2a-4324-fc59-67c5ff935006"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/changing-landscape-and-emerging-trends-in-the-indian-it-ites-industry/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 89.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cafa04f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7cafa04f",
    "outputId": "85e3bcf4-55a9-4de3-888c-d8579cf45b19"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/online-gaming-adolescent-online-gaming-effects-demotivated-depression-musculoskeletal-and-psychosomatic-symptoms/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 90.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cee4a5d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cee4a5d",
    "outputId": "749d6c31-e34e-4523-c982-cf83a180857e"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/human-rights-outlook/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='tdb-title-text').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='tdb-block-inner td-fix-index'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 91.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191f5a00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "191f5a00",
    "outputId": "da6606a5-7dda-4580-e9ab-cdc54a54c155"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-voice-search-makes-your-business-a-successful-business/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='tdb-title-text').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='tdb-block-inner td-fix-index'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 92.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201e5107",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "201e5107",
    "outputId": "214be3fd-711f-4e74-f753-862d2625b6c0"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-the-covid-19-crisis-is-redefining-jobs-and-services/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 93.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83caf65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e83caf65",
    "outputId": "11278026-59ab-499b-846f-1387a8d136d4"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-to-increase-social-media-engagement-for-marketers/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 94.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb61c09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fb61c09",
    "outputId": "52c56e99-c961-4811-db7c-586494bac295"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/impacts-of-covid-19-on-streets-sides-food-stalls/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 95.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7515b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ad7515b7",
    "outputId": "4cb04ab2-556a-4fe3-d4bb-bf1ff175477d"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/coronavirus-impact-on-energy-markets-2/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 96.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a052a77c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a052a77c",
    "outputId": "a5f1c9bf-4150-4db2-d8dc-c9304d74a721"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-5/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 97.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a67aa76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a67aa76",
    "outputId": "b0b4dda2-d885-430d-e256-3710181e9ca5"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-4/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 98.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b2ef15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1b2ef15",
    "outputId": "5c212242-59ce-41bb-9986-5c3e290c98fb"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-2/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 99.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a84d96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1a84d96",
    "outputId": "e10d6021-0ce7-455f-ee8d-73c4e671b2d1"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-3/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='tdb-title-text').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='tdb-block-inner td-fix-index'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 100.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f60f5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8f60f5c",
    "outputId": "8ab8a104-a9a2-44aa-93cb-112620c3af12"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/travel-and-tourism-outlook/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 101.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87584dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e87584dc",
    "outputId": "42ee4b32-b198-45b3-f72f-cfac1292190e"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/gaming-disorder-and-effects-of-gaming-on-health/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 102.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6329de76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6329de76",
    "outputId": "be032e3d-b540-4281-9e8f-2c5a484eebe2"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 103.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41033acb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41033acb",
    "outputId": "fbcc903c-6daf-4d2e-cefc-a07a75cab54f"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation-2/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 104.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a6d94a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38a6d94a",
    "outputId": "10dc3382-043f-4d31-c934-dca0959dc375"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-office-space-and-co-working-industries/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 105.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb02583",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6fb02583",
    "outputId": "599b8a33-3088-4f80-e562-64b3ca088999"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/contribution-of-handicrafts-visual-arts-literature-in-the-indian-economy/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 106.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d58a3ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3d58a3ee",
    "outputId": "f0f6bafe-35ec-4d31-ad16-8e22e267168a"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-covid-19-is-impacting-payment-preferences/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='tdb-title-text').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='tdb-block-inner td-fix-index'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 107.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0600862",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0600862",
    "outputId": "5cd476e4-cc78-45bf-c474-84b31e864e5d"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-2/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='tdb-title-text').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='tdb-block-inner td-fix-index'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 108.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0146be0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0146be0",
    "outputId": "49ecafc8-73ab-4754-9f04-4ede8182796d"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 109.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fb8ec0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6fb8ec0",
    "outputId": "70f94c3b-e698-4ef0-ec3b-cb96bfd9f669"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/covid-19-how-have-countries-been-responding/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 110.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0586b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "be0586b6",
    "outputId": "e867ae7e-4085-4b5a-c43b-f4b71d016c04"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-2/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 111.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db89687a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db89687a",
    "outputId": "b273c6d9-a4f3-44ab-b251-135646bd873c"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-3/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='tdb-title-text').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='tdb-block-inner td-fix-index'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 112.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99e6e46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f99e6e46",
    "outputId": "413fcfba-8c7f-4b55-b9c5-e4f79c9c4a8b"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-3/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 113.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f0dca8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65f0dca8",
    "outputId": "2dc17c58-3300-4f0a-ec56-d217d81df60a"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 114.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd104f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fd104f2",
    "outputId": "6c12dd1b-2792-4a08-e3fb-8089cb50681f"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/covid-19-how-have-countries-been-responding-2/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 115.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31693617",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31693617",
    "outputId": "121968c9-ba37-4186-f551-30baa86e3dac"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-4/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 116.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2683556",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2683556",
    "outputId": "10f27c14-54fd-40ce-a897-221d49210bbe"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-2/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 117.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efa4aba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6efa4aba",
    "outputId": "a3b056bc-8fc5-46d9-e8c5-efdedd45ead4"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-3/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 118.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2f2f03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c2f2f03",
    "outputId": "56250c9a-961c-48ca-f8ac-4aee7a8ef196"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-4/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 119.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a03e0af",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a03e0af",
    "outputId": "9333d54c-8f1b-4e94-f27a-f9a5d5534ef3"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/why-scams-like-nirav-modi-happen-with-indian-banks/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 120.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d096db21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d096db21",
    "outputId": "131ce63f-064b-418d-d717-f294a6e58553"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/impact-of-covid-19-on-the-global-economy/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 121.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113cb98a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "113cb98a",
    "outputId": "c1e96ac5-340f-44fc-a639-cb8ba12476d6"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/impact-of-covid-19coronavirus-on-the-indian-economy-2/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 122.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b52a94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42b52a94",
    "outputId": "64d55b68-f9ab-4217-d495-16b9d34782fd"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/impact-of-covid-19-on-the-global-economy-2/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 123.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960f3b37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "960f3b37",
    "outputId": "94d20186-6cc5-40f1-cc96-5874b97bbc81"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/impact-of-covid-19-coronavirus-on-the-indian-economy-3/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 124.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1420d06d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1420d06d",
    "outputId": "c804b1c2-17aa-49e8-a2b6-e726b9616e80"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/should-celebrities-be-allowed-to-join-politics/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 125.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e611ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76e611ff",
    "outputId": "3ff87282-6be3-4662-c576-f5d15b3ee51d"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-prepared-is-india-to-tackle-a-possible-covid-19-outbreak/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 126.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de6e33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92de6e33",
    "outputId": "7f052ee9-2113-4907-b14f-98bab09d36f8"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 127.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5211791",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5211791",
    "outputId": "36a895bf-97e4-40ba-e917-babd6e4d7525"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/controversy-as-a-marketing-strategy/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 128.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbe005e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bbe005e",
    "outputId": "71894b92-d80a-4fd2-dda4-73837059aae9"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 129.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eca1b60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7eca1b60",
    "outputId": "69e14d94-bca8-4780-a133-2b1c5da49c85"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/coronavirus-impact-on-energy-markets/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 130.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0987741",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0987741",
    "outputId": "bc7b5911-c952-4f58-d1ac-4da304deee11"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/what-are-the-key-policies-that-will-mitigate-the-impacts-of-covid-19-on-the-world-of-work/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 131.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aed231",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2aed231",
    "outputId": "4972bfde-71c7-4dd5-f26f-25b91a67287b"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/marketing-drives-results-with-a-focus-on-problems/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 132.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd9dd84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3dd9dd84",
    "outputId": "ccdfc8e8-cf39-4a51-9f52-e3ec951a11d6"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/continued-demand-for-sustainability/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 133.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7226aab6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7226aab6",
    "outputId": "1869548b-7de0-4858-ebbb-dcd0ad329609"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/coronavirus-disease-covid-19-effect-the-impact-and-role-of-mass-media-during-the-pandemic/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 134.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4eb11c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1f4eb11c",
    "outputId": "5db3fc60-1589-42cc-d886-eb42cf05d12f"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/should-people-wear-fabric-gloves-seeking-evidence-regarding-the-differential-transfer-of-covid-19-or-coronaviruses-generally-between-surfaces/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 135.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d209cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94d209cb",
    "outputId": "b1a9943b-e206-40aa-d969-472cedc60a90"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/why-is-there-a-severe-immunological-and-inflammatory-explosion-in-those-affected-by-sarms-covid-19/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 136.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d896113b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d896113b",
    "outputId": "5cd4c1b9-edbe-4c52-cb71-3f8b293ba088"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/what-do-you-think-is-the-lesson-or-lessons-to-be-learned-with-covid-19/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 137.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1926ab8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1926ab8",
    "outputId": "d16e0192-9e40-432d-b223-f8bb97353482"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/coronavirus-the-unexpected-challenge-for-the-european-union/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 138.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1272863d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1272863d",
    "outputId": "f74db93a-93ce-40ed-e319-73ffa0027909"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/industrial-revolution-4-0-pros-and-cons/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 139.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587e9fbf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "587e9fbf",
    "outputId": "f81056df-fd43-4ba7-d499-fb4df6e17694"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/impact-of-covid-19-coronavirus-on-the-indian-economy/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 140.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd318dc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd318dc9",
    "outputId": "e7d4d108-8df0-4f35-96d2-e3198e91479c"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/impact-of-covid-19-coronavirus-on-the-indian-economy-2/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 141.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5226e1ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5226e1ef",
    "outputId": "00a95fbb-5a7c-470c-8ac8-948743b1e715"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/impact-of-covid-19coronavirus-on-the-indian-economy/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 142.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f820c1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8f820c1a",
    "outputId": "acf46f4b-bd35-4dec-cbbe-1d2925e4069f"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/impact-of-covid-19-coronavirus-on-the-global-economy/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 143.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431db9ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "431db9ff",
    "outputId": "658f3e65-38c0-4953-9935-b31f081c9648"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/ensuring-growth-through-insurance-technology/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h3', class_='tdm-title tdm-title-md').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='tds-button td-fix-index'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 144.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b855a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23b855a2",
    "outputId": "f114ca6d-0a28-4c76-e133-671e2e8363b8"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/blockchain-in-fintech/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 145.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c81e5e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c81e5e4",
    "outputId": "8206fd8c-da36-42a6-8aad-019d6e3e13d8"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/blockchain-for-payments/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 146.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7328f93",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7328f93",
    "outputId": "0609f8ca-e0dc-4c29-c40c-efd51f689d2b"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/the-future-of-investing/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 147.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604c736b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "604c736b",
    "outputId": "93f98ac0-636b-458e-9c51-23fb47a1c7ea"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/big-data-analytics-in-healthcare/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 148.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcef909",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abcef909",
    "outputId": "2aa21580-bb29-4a99-b591-a5e5a0500281"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/business-analytics-in-the-healthcare-industry/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 149.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536cdb1d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "536cdb1d",
    "outputId": "6df3ffc5-0e54-460a-eab7-6f513b63ad23"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/challenges-and-opportunities-of-big-data-in-healthcare/\"\n",
    "\n",
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the title and article text\n",
    "title = soup.find('h1', class_='entry-title').text.strip()\n",
    "article_text = ''\n",
    "for paragraph in soup.find_all('div', class_='td-post-content tagdiv-type'):\n",
    "    article_text += paragraph.text.strip()\n",
    "\n",
    "# Print the title and article text\n",
    "print(\"Title:\", title)\n",
    "print(\"Article Text:\", article_text)\n",
    "\n",
    "# Save the title and article text to a text file\n",
    "filename = \"URL_ID 150.txt\"\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(title + \"\\n\\n\")\n",
    "    file.write(article_text)\n",
    "print(\"Article saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98efaa5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c98efaa5",
    "outputId": "5b68daee-21bd-4e3d-89a8-aaabb4dc0536"
   },
   "outputs": [],
   "source": [
    "pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167de80e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "167de80e",
    "outputId": "8d643073-bd3e-4f15-d58d-ac947b1e70ff"
   },
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978eed4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "978eed4d",
    "outputId": "323f3715-63a6-4e78-c3ee-7dc33e0890f2"
   },
   "outputs": [],
   "source": [
    "pip install pyphen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f2e5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1f6f2e5c",
    "outputId": "574b0071-2fe4-4bd0-aaf4-1d6c5284908e"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import pandas as pd\n",
    "import pyphen\n",
    "from textblob import TextBlob\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Define a set of common suffixes for complex words\n",
    "complex_suffixes = set([\"able\", \"ible\", \"al\", \"ial\", \"ed\", \"en\", \"er\", \"est\", \"ful\", \"ic\", \"ing\", \"ion\", \"tion\", \"ation\", \"ition\", \"ity\", \"ty\", \"ive\", \"ative\", \"itive\", \"less\", \"ly\", \"ment\", \"ness\", \"ous\", \"eous\", \"ious\", \"s\", \"es\", \"y\"])\n",
    "\n",
    "# Define a list of file names to process\n",
    "file_list = [\n",
    "    \"URL_ID 37.txt\", \"URL_ID 38.txt\", \"URL_ID 39.txt\", \"URL_ID 40.txt\", \"URL_ID 41.txt\",\n",
    "    \"URL_ID 42.txt\", \"URL_ID 43.txt\", \"URL_ID 44.txt\", \"URL_ID 45.txt\", \"URL_ID 46.txt\",\n",
    "    \"URL_ID 47.txt\", \"URL_ID 48.txt\", \"URL_ID 49.txt\", \"URL_ID 50.txt\", \"URL_ID 51.txt\",\n",
    "    \"URL_ID 52.txt\", \"URL_ID 53.txt\", \"URL_ID 54.txt\", \"URL_ID 55.txt\", \"URL_ID 56.txt\",\n",
    "    \"URL_ID 57.txt\", \"URL_ID 58.txt\", \"URL_ID 59.txt\", \"URL_ID 60.txt\", \"URL_ID 61.txt\",\n",
    "    \"URL_ID 62.txt\", \"URL_ID 63.txt\", \"URL_ID 64.txt\", \"URL_ID 65.txt\", \"URL_ID 66.txt\",\n",
    "    \"URL_ID 67.txt\", \"URL_ID 68.txt\", \"URL_ID 69.txt\", \"URL_ID 70.txt\", \"URL_ID 71.txt\",\n",
    "    \"URL_ID 72.txt\", \"URL_ID 73.txt\", \"URL_ID 74.txt\", \"URL_ID 75.txt\", \"URL_ID 76.txt\",\n",
    "    \"URL_ID 77.txt\", \"URL_ID 78.txt\", \"URL_ID 79.txt\", \"URL_ID 80.txt\", \"URL_ID 81.txt\",\n",
    "    \"URL_ID 82.txt\", \"URL_ID 83.txt\", \"URL_ID 84.txt\", \"URL_ID 85.txt\", \"URL_ID 86.txt\",\n",
    "    \"URL_ID 87.txt\", \"URL_ID 88.txt\", \"URL_ID 89.txt\", \"URL_ID 90.txt\", \"URL_ID 91.txt\",\n",
    "    \"URL_ID 92.txt\", \"URL_ID 93.txt\", \"URL_ID 94.txt\", \"URL_ID 95.txt\", \"URL_ID 96.txt\",\n",
    "    \"URL_ID 97.txt\", \"URL_ID 98.txt\", \"URL_ID 99.txt\", \"URL_ID 100.txt\", \"URL_ID 101.txt\",\n",
    "    \"URL_ID 102.txt\", \"URL_ID 103.txt\", \"URL_ID 104.txt\", \"URL_ID 105.txt\", \"URL_ID 106.txt\",\n",
    "    \"URL_ID 107.txt\", \"URL_ID 108.txt\", \"URL_ID 109.txt\", \"URL_ID 110.txt\", \"URL_ID 111.txt\",\n",
    "    \"URL_ID 112.txt\", \"URL_ID 113.txt\", \"URL_ID 114.txt\", \"URL_ID 115.txt\", \"URL_ID 116.txt\",\n",
    "    \"URL_ID 117.txt\", \"URL_ID 118.txt\", \"URL_ID 119.txt\", \"URL_ID 120.txt\", \"URL_ID 121.txt\",\n",
    "    \"URL_ID 122.txt\", \"URL_ID 123.txt\", \"URL_ID 124.txt\", \"URL_ID 125.txt\", \"URL_ID 126.txt\",\n",
    "    \"URL_ID 127.txt\", \"URL_ID 128.txt\", \"URL_ID 129.txt\", \"URL_ID 130.txt\", \"URL_ID 131.txt\",\n",
    "    \"URL_ID 132.txt\", \"URL_ID 133.txt\", \"URL_ID 134.txt\", \"URL_ID 135.txt\", \"URL_ID 136.txt\",\n",
    "    \"URL_ID 137.txt\", \"URL_ID 138.txt\", \"URL_ID 139.txt\", \"URL_ID 140.txt\", \"URL_ID 141.txt\", \"URL_ID 142.txt\", \"URL_ID 143.txt\", \"URL_ID 144.txt\", \"URL_ID 145.txt\", \"URL_ID 146.txt\", \"URL_ID 147.txt\", \"URL_ID 148.txt\", \"URL_ID 149.txt\", \"URL_ID 150.txt\"]\n",
    "\n",
    "# Initialize an empty list to store the resulting dataframes\n",
    "result_dfs = []\n",
    "\n",
    "\n",
    "# Loop through the file list and perform the analysis on each file\n",
    "for filename in file_list:\n",
    "    # Load the article text\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        article_text = file.read()\n",
    "\n",
    "    # Tokenize the text into sentences and words\n",
    "    sentences = nltk.sent_tokenize(article_text)\n",
    "    words = nltk.word_tokenize(article_text)\n",
    "\n",
    "    # Initialize the syllable counter\n",
    "    dic = pyphen.Pyphen(lang='en')\n",
    "\n",
    "    # Calculate various statistics on the tokens\n",
    "    word_count = len(words)\n",
    "    sentence_count = len(sentences)\n",
    "    syllable_count = sum([len(dic.inserted(word).split(\"-\")) for word in words])\n",
    "    avg_sentence_length = word_count / sentence_count\n",
    "    avg_word_length = syllable_count / word_count\n",
    "    complex_word_count = sum([1 for word in words if any(suffix in word[-6:] for suffix in complex_suffixes)])\n",
    "    complex_word_percentage = complex_word_count / word_count * 100\n",
    "\n",
    "    # Create a dataframe with the analysis results\n",
    "    df = pd.DataFrame({\n",
    "        'Filename': [filename],\n",
    "        'Word Count': [word_count],\n",
    "        'Sentence Count': [sentence_count],\n",
    "        'Syllable Count': [syllable_count],\n",
    "        'Avg Sentence Length': [avg_sentence_length],\n",
    "        'Avg Word Length': [avg_word_length],\n",
    "        'Complex Word Count': [complex_word_count],\n",
    "        'Complex Word Percentage': [complex_word_percentage]\n",
    "    })\n",
    "\n",
    "    # Append the resulting dataframe to the list\n",
    "    result_dfs.append(df)\n",
    "\n",
    "# Concatenate all the resulting dataframes into a single dataframe\n",
    "result_df = pd.concat(result_dfs, ignore_index=True)\n",
    "\n",
    "# Save the resulting dataframe to an Excel file\n",
    "with pd.ExcelWriter('output.xlsx') as writer:\n",
    "    result_df.to_excel(writer, index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_3u-IbTNgUVv",
   "metadata": {
    "id": "_3u-IbTNgUVv"
   },
   "outputs": [],
   "source": [
    "df2=pd.read_excel(\"/content/Output Data Structure.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yZrIOFRnge8u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZrIOFRnge8u",
    "outputId": "9d49aa8c-ecf1-40c1-bfb2-94304d857599"
   },
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nzxS2u1zhI4S",
   "metadata": {
    "id": "nzxS2u1zhI4S"
   },
   "outputs": [],
   "source": [
    "df2.drop([ 'URL_ID','POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE',\n",
    "       'SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH',\n",
    "       'PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX',\n",
    "       'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT', 'WORD COUNT',\n",
    "       'SYLLABLE PER WORD','PERSONAL PRONOUNS','AVG WORD LENGTH'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yj1YAK6mhaBd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yj1YAK6mhaBd",
    "outputId": "82cc1a64-f060-4c0f-b5fd-20660dca28ae"
   },
   "outputs": [],
   "source": [
    "df2.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QKPGRppOhf5C",
   "metadata": {
    "id": "QKPGRppOhf5C"
   },
   "outputs": [],
   "source": [
    "df3=pd.read_excel(\"/content/output.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9luJgtMLhlxx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9luJgtMLhlxx",
    "outputId": "27ee81cb-f7eb-4d31-e29d-a0d82e8164c1"
   },
   "outputs": [],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Orx1d6mGh8z7",
   "metadata": {
    "id": "Orx1d6mGh8z7"
   },
   "outputs": [],
   "source": [
    "df2=df2.join(df3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DDUeUTtvjxw6",
   "metadata": {
    "id": "DDUeUTtvjxw6"
   },
   "outputs": [],
   "source": [
    "df2.to_excel('data.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
